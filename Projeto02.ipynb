{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Classificador Automático de Sentimento\n",
    "\n",
    "Você foi contratado por uma empresa parar analisar como os clientes estão reagindo a um determinado produto no Twitter. A empresa deseja que você crie um programa que irá analisar as mensagens disponíveis e classificará como \"relevante\" ou \"irrelevante\". Com isso ela deseja que mensagens negativas, que denigrem o nome do produto, ou que mereçam destaque, disparem um foco de atenção da área de marketing.<br /><br />\n",
    "Como aluno de Ciência dos Dados, você lembrou do Teorema de Bayes, mais especificamente do Classificador Naive-Bayes, que é largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser relevante dadas as palavras em seu conteúdo.<br /><br />\n",
    "Para realizar o MVP (*minimum viable product*) do projeto, você precisa implementar uma versão do classificador que \"aprende\" o que é relevante com uma base de treinamento e compara a performance dos resultados com uma base de testes.<br /><br />\n",
    "Após validado, o seu protótipo poderá também capturar e classificar automaticamente as mensagens da plataforma.\n",
    "\n",
    "## Informações do Projeto\n",
    "\n",
    "Prazo: 13/Set até às 23:59.<br />\n",
    "Grupo: 1 ou 2 pessoas.<br /><br />\n",
    "Entregáveis via GitHub: \n",
    "* Arquivo notebook com o código do classificador, seguindo as orientações abaixo.\n",
    "* Arquivo Excel com as bases de treinamento e teste totalmente classificado.\n",
    "\n",
    "**NÃO disponibilizar o arquivo com os *access keys/tokens* do Twitter.**\n",
    "\n",
    "\n",
    "### Check 3: \n",
    "\n",
    "Até o dia 06 de Setembro às 23:59, o notebook e o xlsx devem estar no Github com as seguintes evidências: \n",
    "    * Conta no twitter criada.\n",
    "    * Produto escolhido.\n",
    "    * Arquivo Excel contendo a base de treinamento e teste já classificado.\n",
    "\n",
    "Sugestão de leitura:<br />\n",
    "http://docs.tweepy.org/en/v3.5.0/index.html<br />\n",
    "https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Preparando o ambiente\n",
    "\n",
    "Instalando a biblioteca *tweepy* para realizar a conexão com o Twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Instalando o tweepy\n",
    "#!pip install tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando as Bibliotecas que serão utilizadas. Esteja livre para adicionar outras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle\n",
    "from functools import reduce\n",
    "from operator import mul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "Para realizar a captura dos dados é necessário ter uma conta cadastrada no twitter:\n",
    "\n",
    "* Conta: ***[Preencha aqui o id da sua conta. Ex: @fulano ]***\n",
    "\n",
    "\n",
    "1. Caso ainda não tenha uma: https://twitter.com/signup\n",
    "1. Depois é necessário registrar um app para usar a biblioteca: https://apps.twitter.com/\n",
    "1. Dentro do registro do App, na aba Keys and Access Tokens, anotar os seguintes campos:\n",
    "    1. Consumer Key (API Key)\n",
    "    1. Consumer Secret (API Secret)\n",
    "1. Mais abaixo, gere um Token e anote também:\n",
    "    1. Access Token\n",
    "    1. Access Token Secret\n",
    "    \n",
    "1. Preencha os valores no arquivo \"auth.pass\"\n",
    "\n",
    "**ATENÇÃO**: Nunca divulgue os dados desse arquivo online (GitHub, etc). Ele contém as chaves necessárias para realizar as operações no twitter de forma automática e portanto é equivalente a ser \"hackeado\". De posse desses dados, pessoas mal intencionadas podem fazer todas as operações manuais (tweetar, seguir, bloquear/desbloquear, listar os seguidores, etc). Para efeito do projeto, esse arquivo não precisa ser entregue!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dados de autenticação do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @fulano\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. Não modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Coletando Dados\n",
    "\n",
    "Agora vamos coletar os dados. Tenha em mente que dependendo do produto escolhido, não haverá uma quantidade significativa de mensagens, ou ainda poder haver muitos retweets.<br /><br /> \n",
    "Configurando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = 'fifa 17'\n",
    "\n",
    "#Quantidade mínima de mensagens capturadas:\n",
    "n = 500\n",
    "#Quantidade mínima de mensagens para a base de treinamento:\n",
    "t = 300\n",
    "\n",
    "#Filtro de língua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documentação do tweepy\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang).items():    \n",
    "    msgs.append(msg.text.lower())\n",
    "    i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um possível viés\n",
    "shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo não existe para não substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificando as Mensagens\n",
    "\n",
    "Agora você deve abrir o arquivo Excel com as mensagens capturadas e classificar na Coluna B se a mensagem é relevante ou não.<br /> \n",
    "Não se esqueça de colocar um nome para a coluna na célula **B1**.<br /><br />\n",
    "Fazer o mesmo na planilha de Controle.\n",
    "\n",
    "___\n",
    "## Montando o Classificador Naive-Bayes\n",
    "\n",
    "Com a base de treinamento montada, comece a desenvolver o classificador. Escreva o seu código abaixo:\n",
    "\n",
    "Opcionalmente: \n",
    "* Limpar as mensagens removendo os caracteres: enter, :, \", ', (, ), etc. Não remover emojis.<br />\n",
    "* Corrigir separação de espaços entre palavras e/ou emojis.\n",
    "* Propor outras limpezas/transformações que não afetem a qualidade da informação.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Treinamento', 'Teste']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xl=pd.ExcelFile(\"fifa 17.xlsx\")\n",
    "xl.sheet_names\n",
    "[u'Treinamento', u'Teste']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = xl.parse(\"Treinamento\")\n",
    "\n",
    "df['Treinamento'] = df['Treinamento'].str.replace(\",\",\"\")\n",
    "df['Treinamento'] = df['Treinamento'].str.replace(\".\",\"\")\n",
    "df['Treinamento'] = df['Treinamento'].str.replace(\"'\",\"\")\n",
    "df['Treinamento'] = df['Treinamento'].str.replace('\"',\"\")\n",
    "df['Treinamento'] = df['Treinamento'].str.replace(\"  \",\" \")\n",
    "df['Treinamento'] = df['Treinamento'].str.replace(\" a \",\" \")\n",
    "df['Treinamento'] = df['Treinamento'].str.replace(\" as \",\" \")\n",
    "df['Treinamento'] = df['Treinamento'].str.replace(\" o \",\" \")\n",
    "df['Treinamento'] = df['Treinamento'].str.replace(\" os \",\" \")\n",
    "df['Treinamento'] = df['Treinamento'].str.replace(\")\",\"\")\n",
    "df['Treinamento'] = df['Treinamento'].str.replace(\"(\",\"\")\n",
    "df['Treinamento'] = df['Treinamento'].str.replace(\"-\",\"\")\n",
    "df['Treinamento'] = df['Treinamento'].str.replace(\"!\",\"\")\n",
    "df['Treinamento'] = df['Treinamento'].str.replace(\"?\",\"\")\n",
    "\n",
    "df['Treinamento'] = df['Treinamento'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = xl.parse(\"Teste\")\n",
    "\n",
    "df2['Teste'] = df2['Teste'].str.replace(\",\",\"\")\n",
    "df2['Teste'] = df2['Teste'].str.replace(\".\",\"\")\n",
    "df2['Teste'] = df2['Teste'].str.replace(\"'\",\"\")\n",
    "df2['Teste'] = df2['Teste'].str.replace('\"',\"\")\n",
    "df2['Teste'] = df2['Teste'].str.replace(\"  \",\" \")\n",
    "df2['Teste'] = df2['Teste'].str.replace(\" a \",\" \")\n",
    "df2['Teste'] = df2['Teste'].str.replace(\" as \",\" \")\n",
    "df2['Teste'] = df2['Teste'].str.replace(\" o \",\" \")\n",
    "df2['Teste'] = df2['Teste'].str.replace(\" os \",\" \")\n",
    "df2['Teste'] = df2['Teste'].str.replace(\")\",\"\")\n",
    "df2['Teste'] = df2['Teste'].str.replace(\"(\",\"\")\n",
    "df2['Teste'] = df2['Teste'].str.replace(\"-\",\"\")\n",
    "df2['Teste'] = df2['Teste'].str.replace(\"!\",\"\")\n",
    "df2['Teste'] = df2['Teste'].str.replace(\"?\",\"\")\n",
    "\n",
    "df2['Teste'] = df2['Teste'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def repetido(a):\n",
    "    return list(set(a))\n",
    "\n",
    "\n",
    "\n",
    "relevante = []\n",
    "relevante_srep = []\n",
    "n_relevante = []\n",
    "n_relevante_srep = []\n",
    "todas = []\n",
    "todas_srep = []\n",
    "\n",
    "for i in range(len(df)): \n",
    "    todas+=(list(df[\"Treinamento\"][i].split()))\n",
    "    \n",
    "\n",
    "for i in range(len(df)):\n",
    "    if df[\"B1\"][i]==1:\n",
    "        relevante+=(list(df[\"Treinamento\"][i].split()))\n",
    "        \n",
    "    if df[\"B1\"][i]==2:\n",
    "        n_relevante+=(list(df[\"Treinamento\"][i].split()))\n",
    "        \n",
    "        \n",
    "\n",
    "relevante_srep = repetido(relevante)\n",
    "n_relevante_srep = repetido(n_relevante)\n",
    "todas_srep = repetido(todas)\n",
    "\n",
    "\n",
    "numero_relevante = len(relevante)\n",
    "numero_relevante_srep = len(relevante_srep)\n",
    "numero_n_relevante= len(n_relevante)\n",
    "numero_n_relevante_srep= len(n_relevante_srep)\n",
    "numero_todas = len(todas)\n",
    "numero_todas_srep = len(todas_srep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "palavra_relevante={}\n",
    "pr=[]\n",
    "\n",
    "i=0\n",
    "while i<len(relevante):\n",
    "    if relevante[i] in palavra_relevante:\n",
    "        palavra_relevante[relevante[i]]=palavra_relevante[relevante[i]]+1\n",
    "    else:\n",
    "        palavra_relevante[relevante[i]]=1\n",
    "        pr.append(relevante[i])\n",
    "        \n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "palavra_n_relevante={}\n",
    "pnr=[]\n",
    "\n",
    "i=0\n",
    "while i<len(n_relevante):\n",
    "    if n_relevante[i] in palavra_n_relevante:\n",
    "        palavra_n_relevante[n_relevante[i]]=palavra_n_relevante[n_relevante[i]]+1\n",
    "    else:\n",
    "        palavra_n_relevante[n_relevante[i]]=1\n",
    "        pnr.append(n_relevante[i])\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "palavra_prob_relevante={}\n",
    "palavra_prob_nrelevante={}\n",
    "\n",
    "i=0\n",
    "while i<len(relevante):\n",
    "    palavra_prob_relevante[relevante[i]]=((palavra_relevante[relevante[i]]+1)/(numero_relevante+numero_todas_srep))\n",
    "    i+=1\n",
    "    \n",
    "while i<len(n_relevante):\n",
    "    palavra_prob_nrelevante[n_relevante[i]]=((palavra_n_relevante[n_relevante[i]]+1)/(numero_n_relevante+numero_todas_srep))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu Classificador com a base de Testes.<br /><br /> \n",
    "\n",
    "Você deve extrair as seguintes medidas:\n",
    "* Porcentagem de positivos falsos (marcados como relevante mas não são relevantes)\n",
    "* Porcentagem de positivos verdadeiros (marcado como relevante e são relevantes)\n",
    "* Porcentagem de negativos verdadeiros (marcado como não relevante e não são relevantes)\n",
    "* Porcentagem de negativos falsos (marcado como não relevante e são relevantes)\n",
    "\n",
    "Opcionalmente:\n",
    "* Criar categorias intermediárias de relevância baseado na diferença de probabilidades. Exemplo: muito relevante, relevante, neutro, irrelevante e muito irrelevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "teste=[]\n",
    "probabilidade_relevante_t=[]\n",
    "probabilidade_n_relevante_t=[]\n",
    "\n",
    "\n",
    "for i in df2[\"Teste\"]:\n",
    "    a=i.split()\n",
    "    teste.append(a)\n",
    "    \n",
    "    \n",
    "    \n",
    "for t in teste:\n",
    "    p=[1]\n",
    "    for e in t:\n",
    "        if e in palavra_prob_relevante:\n",
    "            p.append(palavra_prob_relevante[e])\n",
    "        else:\n",
    "            v = 1 / (numero_relevante + numero_todas_srep)\n",
    "            p.append(v)\n",
    "            \n",
    "    a = reduce(mul,p)\n",
    "    probabilidade_relevante_t.append(a)\n",
    "    \n",
    "    \n",
    "    \n",
    "for t in teste:\n",
    "    p=[1]\n",
    "    for e in t:\n",
    "        if e in palavra_prob_nrelevante:\n",
    "            p.append(palavra_prob_nrelevante[e])\n",
    "        else:\n",
    "            v = 1 / (numero_n_relevante + numero_todas_srep)\n",
    "            p.append(v)\n",
    "            \n",
    "    a = reduce(mul,p)\n",
    "    probabilidade_n_relevante_t.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listaFinalRelevancia = []\n",
    "i=0\n",
    "while i <(len(teste)):\n",
    "    if probabilidade_relevante_t[i] > probabilidade_n_relevante_t[i]:\n",
    "        a=1\n",
    "        listaFinalRelevancia.append(a)\n",
    "        \n",
    "        \n",
    "    elif probabilidade_relevante_t[i] < probabilidade_n_relevante_t[i]:\n",
    "        a=2\n",
    "        listaFinalRelevancia.append(a)\n",
    "        \n",
    "       \n",
    "    elif probabilidade_relevante_t[i] == probabilidade_n_relevante_t[i]:\n",
    "        a=0\n",
    "        listaFinalRelevancia.append(a)\n",
    "        \n",
    "    i+=1\n",
    "    \n",
    "\n",
    "    \n",
    "df2[\"B1\"] = pd.Series(listaFinalRelevancia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Certo           27.0\n",
       "Falso Certo      7.0\n",
       "Errado          63.0\n",
       "Falso Errado     3.0\n",
       "Name: B3, dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados=[]\n",
    "\n",
    "for i in range(len(listaFinalRelevancia)):\n",
    "    if df2[\"B1\"][i] == 1  and df2[\"B2\"][i] == 1:\n",
    "        resultados.append(\"Certo\")\n",
    "        \n",
    "    if df2[\"B1\"][i] == 1  and df2[\"B2\"][i] == 2:\n",
    "        resultados.append(\"Falso Certo\")\n",
    "        \n",
    "    if df2[\"B1\"][i] == 2  and df2[\"B2\"][i] == 2:\n",
    "        resultados.append(\"Errado\")\n",
    "        \n",
    "    if df2[\"B1\"][i] == 2  and df2[\"B2\"][i] == 1:\n",
    "        resultados.append(\"Falso Errado\")\n",
    "        \n",
    "df2[\"B3\"] = pd.Series(resultados) \n",
    "\n",
    "\n",
    "(df2[\"B3\"].value_counts(normalize=True)*100).round(decimals=1).reindex(['Certo', 'Falso Certo','Errado','Falso Errado'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sucesso    90.0\n",
       "Falha      10.0\n",
       "Name: B4, dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fFinal = []\n",
    "for i in range(len(listaFinalRelevancia)):\n",
    "    if df2[\"B3\"][i] == \"Certo\"  or df2[\"B3\"][i] == \"Errado\":\n",
    "        fFinal.append(\"Sucesso\")\n",
    "    if df2[\"B3\"][i] == \"Falso Certo\"  or df2[\"B3\"][i] == \"Falso Errado\":\n",
    "        fFinal.append(\"Falha\")\n",
    "    \n",
    "        \n",
    "df2[\"B4\"] = pd.Series(fFinal)\n",
    "\n",
    "(df2[\"B4\"].value_counts(normalize=True)*100).round(decimals=1).reindex(['Sucesso', 'Falha'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('fifa 17.xlsx')\n",
    "df.to_excel(writer,'Treinamento')\n",
    "df2.to_excel(writer,'Teste')\n",
    "writer.save()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "___\n",
    "## Concluindo\n",
    "\n",
    "Escreva aqui a sua conclusão.<br /> \n",
    "Faça um comparativo qualitativo sobre as medidas obtidas.<br />\n",
    "Explique como são tratadas as mensagens com dupla negação e sarcasmo.<br />\n",
    "Proponha um plano de expansão. Por que eles devem continuar financiando o seu projeto?<br />\n",
    "\n",
    "Opcionalmente: \n",
    "* Discorrer por que não posso alimentar minha base de Treinamento automaticamente usando o próprio classificador, aplicado a novos tweets.\n",
    "* Propor diferentes cenários de uso para o classificador Naive-Bayes. Cenários sem intersecção com este projeto.\n",
    "* Sugerir e explicar melhorias reais no classificador com indicações concretas de como implementar (não é preciso codificar, mas indicar como fazer e material de pesquisa sobre o assunto).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "   Fizemos um classificador para ensinar a máquina a classificar tweets relacionados ao nosso produto em relevantes ou não relevantes. O produto escolhido foi o Fifa 2017, um dos jogos virtuais mais populares no mundo que sempre gera uma grande quantidade de comentários sobre. Procuramos fazer um classificador que identificassem os comentários relevantes sobre o game, ou seja que fornecessem alguma forma de feedback sobre a experiência dos usuários.\n",
    "\n",
    "   Com os tweets processados pelo classificador, obtivemos 27% de certos relevantes (o classificador e nós consideramos relevante), 7% de falsos relevantes (o classificador considera relevante mas nós não), 63% de certos irrelevantes (o classificador e nós consideramos irrelevantes) e 3% de falsos irrelevantes (o classificador considera irrelevante mas nós não). No total, o classificador acertou 90% da relevância dos tweets em relação a nossa definição de relevância e irrelevância.\n",
    "\n",
    "   Mensagens com dupla negação e sarcasmo não interferem no processamento do classificador pois mesmo contendo alguma das duas, elas não mudam o fato do tweet ser considerado um feedback ou não. \n",
    "   \n",
    "   Num futuro próximo, o classificador poderá ser otimizado com alguns passos já traçados. Como unir alguns verbos que estão conjugados de maneiras diferentes em uma só palavra, palavras que tem algumas variações também. Aumentar a base de tweets inicial para assim ter um banco de palavras maior e com as probabilidades de cada uma mais precisas. Isso seria muito vantajoso para detectar a satisfação do público e as correções que devem ser feitas para o futuro da série."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
